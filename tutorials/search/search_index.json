{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"apps/deploying-bugsink-to-dokku/","title":"Deploying Bugsink to Dokku","text":"<p>Bugsink is a sentry-compatible Error Tracker with a strong focus on being very easy to self-host.</p> <p>That focus makes it an excellent candidate for deployment on Dokku, as it is a simple application that can be deployed with minimal configuration.</p> <p>This tutorial explains how to deploy a self-hosted instance of Bugsink on a Dokku server. It assumes:</p> <ul> <li>You have a working Dokku setup with SSH access</li> <li>The domain is already pointing to your Dokku server.</li> <li>Subdomains to your domain also point to your Dokku server.</li> </ul>","tags":["dokku","bugsink","tutorial"]},{"location":"apps/deploying-bugsink-to-dokku/#set-up-a-mysql-service","title":"Set up a MySQL service","text":"<p>Bugsink can use either SQLite, MySQL or Postgres as its database backend. SQLite is actually a surprisingly stable and performant way to run Bugsink, but in cloud-like environments (such as dokku) it's usually a better fit to use a separate database service, as this allows for persistent storage across container restarts. In this tutorial we'll pick MySQL.</p> <p>We'll set up the MySQL service first, so that it's there waiting for us when we set up Bugsink itself.</p> <p>Install the official MySQL plugin for Dokku:</p> <pre><code># on your dokku host\nsudo dokku plugin:install https://github.com/dokku/dokku-mysql.git --name mysql\n</code></pre> <p>Create a new MySQL service named <code>bugsink-db</code>:</p> <pre><code># on your dokku host\ndokku mysql:create bugsink-db\n</code></pre>","tags":["dokku","bugsink","tutorial"]},{"location":"apps/deploying-bugsink-to-dokku/#create-the-bugsink-app","title":"Create the Bugsink app","text":"<p>Then, we create the actual application. This is the name that will be used to refer to the application in the Dokku CLI.</p> <pre><code># on your dokku host\ndokku apps:create bugsink\n</code></pre> <p>We also instruct Dokku to keep the git directory of the application. This is needed because when deploying Bugsink from source (as we are doing in this tutorial) Bugsink needs the <code>.dit</code> directory to figure out what its version number is.</p> <pre><code># on your dokku host\ndokku git:set bugsink keep-git-dir true\n</code></pre> <p>Finally, we link the database to our application:</p> <pre><code># on your dokku host\ndokku mysql:link bugsink-db bugsink\n</code></pre> <p>This will set the <code>DATABASE_URL</code> environment variable in your application, pointing to the MySQL database.</p>","tags":["dokku","bugsink","tutorial"]},{"location":"apps/deploying-bugsink-to-dokku/#setting-environment-variables","title":"Setting environment variables","text":"<p>Bugsink needs a few more environment variables</p> <pre><code># on your dokku host\ndokku config:set bugsink \\\n    CREATE_SUPERUSER=admin:SOME_SECRET_PASSWORD\n    SECRET_KEY=$(openssl rand -hex 32) \\\n    BASE_URL=http://bugsink.dokku.me\n</code></pre>","tags":["dokku","bugsink","tutorial"]},{"location":"apps/deploying-bugsink-to-dokku/#pushing-the-bugsink-code","title":"Pushing the Bugsink code","text":"<p>Lets clone Bugsink locally (it's source available, so we can push it to our dokku server.</p> <pre><code># on your local machine\ncd some-base-dir\ngit clone git@github.com:bugsink/bugsink.git\ncd bugsink\n</code></pre> <p>When pushing an application, you need to set the dokku host. For the purposes of this tutorial, the hostname of our dokku server is <code>dokku.me</code>. Note that the application name - <code>bugsink</code> in this case - should be appended to the remote so that dokku knows what application you are pushing.</p> <pre><code># on your local machine\ngit remote add dokku dokku@dokku.me:bugsink\ngit push dokku main\n</code></pre> <p>This should print a bunch of logs on screen, showing the successful installation of Bugsink.</p> <p>Now, navigate to bugsink.dokku.me. You should see the Bugsink login screen there. Log in with the credentials you provided while setting up the environment variables. You can now connect SDKs and start sending events</p>","tags":["dokku","bugsink","tutorial"]},{"location":"apps/deploying-bugsink-to-dokku/#wrap-up","title":"Wrap-up","text":"<p>As we displayed above, Dokku's rich featureset allows developers to quickly and easily setup applications. In this case, the application has been optimized for easy deployment using Docker.</p> <p>Dokku is a great tool to have in your deployment arsenal.</p>","tags":["dokku","bugsink","tutorial"]},{"location":"apps/deploying-gogs-to-dokku/","title":"Deploying Gogs to Dokku","text":"<p>Hot off the release of Dokku 0.6.3, here is a sweet tutorial made possible by the new port handling feature of Dokku.</p> <p>Info</p> <p>If you're using Dokku - especially for commercial purposes - consider donating to project development via Github Sponsors, OpenCollective, or Patreon. Funds go to general development, support, and infrastructure costs.</p>","tags":["dokku","ports","gogs","tutorial"]},{"location":"apps/deploying-gogs-to-dokku/#what-is-gogs","title":"What is Gogs?","text":"<p>Info</p> <p>Gogs (Go Git Service) is a painless self-hosted Git service.</p> <p>But what does that mean? Gogs is a self-hosted git management tool that can be used to host git repositories, issues, and releases on your own server.</p> <p>For this tutorial, we will be deploying gogs to a single Dokku server running at least Dokku 0.6.3. You may upgrade your Dokku instance to this version or install it from scratch. Please setup any ssh keys necessary for pushing applications, as we will not go over initial installation.</p>","tags":["dokku","ports","gogs","tutorial"]},{"location":"apps/deploying-gogs-to-dokku/#application-preparation","title":"Application Preparation","text":"<p>Let's start by creating an application! While Dokku automatically creates an application on push, we will need to initialize some settings before the application will work, so it's best to do this manually.</p> <pre><code>dokku apps:create gogs\n</code></pre> <p>Before we continue, lets ensure that the proper domains and ports are setup for gogs. By default, the include <code>Dockerfile</code> exposes ports <code>3000</code> and <code>22</code> for the <code>http</code> and <code>ssh</code> processes, respectively. We will want our application to listen externally on port <code>80</code>, and will need to expose the <code>ssh</code> port on a different port as <code>22</code> is used by the host. We will not be using TCP load-balancing in our case, and instead will rely on the docker-options plugin to expose ssh properly.</p> <pre><code># expose container `http` port 3000 on host `http` port 80\ndokku proxy:ports-add gogs http:80:3000\n\n# expose the container port 22 on host port 2222\ndokku docker-options:add gogs deploy -p 2222:22\n</code></pre> <p></p> <p>Next, we need to ensure there is persistent storage for Gogs. The Gogs docker image uses a directory mounted in <code>/data</code>, and we'll need either a docker volume or host directory to contain this data. For our purposes, we'll use a directory on the host.</p> <p>Info</p> <p>The official recommendation is to place persistent storage in the <code>/var/lib/dokku/data/storage</code> directory for cases where a user is not using a docker volume. As such, we'll create a subdirectory there for our application.</p> <pre><code># create the directory\nmkdir -p /var/lib/dokku/data/storage/gogs\n\n# ensure the proper permissions are set for the gogs directory\nchown -R dokku:dokku /var/lib/dokku/data/storage/gogs\n</code></pre> <p>We can now mount the directory as persistent storage using the official <code>storage</code> plugin. The storage plugin does not check that the directory or volume exists, hence the need to create it beforehand.</p> <pre><code>dokku storage:mount gogs /var/lib/dokku/data/storage/gogs:/data\n</code></pre> <p>At this point, we need to setup our database for gogs. We will use the official dokku-mysql plugin, though you are welcome to use the dokku-postgres plugin or any other MySQL/Postgres installation you choose.</p> <pre><code>dokku plugin:install https://github.com/dokku/dokku-mysql.git mysql\ndokku mysql:create gogs\ndokku mysql:link gogs gogs\n</code></pre> <p></p>","tags":["dokku","ports","gogs","tutorial"]},{"location":"apps/deploying-gogs-to-dokku/#pushing-our-code","title":"Pushing our Code","text":"<p>Lets clone gogs locally. I have a ~/src directory in which I place all the applications I am currently working on and deploying, though any such directory should be fine.</p> <pre><code>git clone git@github.com:gogits/gogs.git ~/src/gogs\n</code></pre> <p>When pushing an application, you need to set the dokku host. For the purposes of this tutorial, the hostname of our dokku server is <code>dokku.me</code>. Note that the application name - <code>gogs</code> in this case - should be appended to the remote so that dokku knows what application you are pushing.</p> <pre><code>git remote add dokku dokku@dokku.me:gogs\n</code></pre> <p>And finally you can trigger a push of the gogs repository to your dokku server. This push will take a while as a few things need to happen:</p> <ul> <li>The actual repository needs to be pushed to your server</li> <li>The docker image must be built</li> </ul> <p>Not to worry though! Everything from this point on is cake :)</p> <pre><code>git push dokku master\n</code></pre>","tags":["dokku","ports","gogs","tutorial"]},{"location":"apps/deploying-gogs-to-dokku/#configuring-gogs","title":"Configuring Gogs","text":"<p>Here is where it gets slightly tricky. You will want to use the following settings to configure Gogs:</p> <ul> <li>MySQL connection information can be retrieved from <code>dokku mysql:info gogs</code></li> <li>Set the SSH port as <code>2222</code>. Gogs will use this to format your projects' SSH connection info in the UI.</li> <li>Do not change the application port.</li> <li>The application url should be changed to match your attached domain. In our case, it would be <code>http://gogs.dokku.me/</code></li> <li>The domain field should also be changed to match your attached domain, but without the 'http'. In our case, it would be <code>gogs.dokku.me</code>. This will also be used to format your projects' connection info the UI.</li> <li>Any of the optional settings can be configured as you wish.</li> </ul> <p>Once you submit the form, you should have a working Gogs Installation!</p> <p></p>","tags":["dokku","ports","gogs","tutorial"]},{"location":"apps/deploying-gogs-to-dokku/#wrap-up","title":"Wrap-up","text":"<p>As we displayed above, Dokku's rich featureset allows developers to quickly and easily setup applications as complex as a git management tool. With it's ability to deploy Dockerfile applications, proxy ports on the fly, and mount persistent storage, Dokku is a great tool to have in your deployment arsenal. Here's hoping it only gets better!</p> <p>If you're using Dokku - especially for commercial purposes - consider donating to project development via Github Sponsors, OpenCollective, or Patreon. Funds go to general development, support, and infrastructure costs.</p>","tags":["dokku","ports","gogs","tutorial"]},{"location":"automation/automating-dokku-setup/","title":"Automating Dokku Application Setup with Ansible","text":"<p>When you deploy an app with Dokku, a common workflow is to create an app on <code>git push</code>:</p> <pre><code>git remote add dokku dokku@dokku.me:app\ngit push dokku master\n</code></pre> <p>This works relatively well, and most folks then stumble through an initial app deploy/configuration cycle. In some cases, a user will create a script to encompass their workflow, or update some document to contain all the commands that were found necessary. However, this fails in at least the following two cases:</p> <ul> <li>The existing server fails in some way, and a new server must be provisioned to quickly service all requests.</li> <li>You need to replicate your deployment process on multiple servers/for multiple services.</li> </ul> <p>We'll evaluate two patterns to solve these problems, both of which are enabled by Dokku's porcelain interfaces.</p> <p>Info</p> <p>If you're using Dokku - especially for commercial purposes - consider donating to project development via Github Sponsors, OpenCollective, or Patreon. Funds go to general development, support, and infrastructure costs.</p>","tags":["dokku","provisioning","automation"]},{"location":"automation/automating-dokku-setup/#running-code-on-server-boot","title":"Running Code on Server Boot","text":"<p>Regardless of whether this is for a single replacement server, or if it is for a series of servers, running code to provision Dokku and necessary applications at boot time is ideal. Doing so will allow us to reduce the amount of time it takes to recover from service failure, as well as make it easier to do this on a fleet of servers. To this end, we can utilize User Data.</p> <p>\"User Data\" is a bit of configuration that can be run by a process called <code>cloud-init</code>. You should consider <code>cloud-init</code> to be the defacto server initialization tool for cloud servers; many popular server providers support it, such as Amazon Web Services, Azure, Digital Ocean, Google Cloud Provider, Linode, etc. Most folks provide user-data in bash script format, but there are many different modules to integrate with <code>cloud-init</code>. As an example, our own docs for Dreamhost support provide installation instructions in <code>yaml</code> format.</p> <p>Here is  the simplest user-data for installing Dokku:</p> <pre><code>#!/bin/bash\nwget https://raw.githubusercontent.com/dokku/dokku/master/bootstrap.sh\nsudo bash bootstrap.sh\n</code></pre> <p>Cloud providers generally have a way to specify user data for either a single server or a set of servers being launched, though the method is different depending on the provider. If your provider does not support user data, our recommendation is to switch to one that does.</p>","tags":["dokku","provisioning","automation"]},{"location":"automation/automating-dokku-setup/#creating-provisioning-an-app-automatically","title":"~~Creating~~ Provisioning an app automatically","text":"<p>Taking this further, lets automatically create an app and configure it for deployment when a server starts</p> <pre><code>#!/bin/bash\nwget https://raw.githubusercontent.com/dokku/dokku/master/bootstrap.sh\nsudo bash bootstrap.sh\n\nexport APP_NAME=\"node-js-app\"\ndokku apps:exists \"$APP_NAME\" || dokku apps:create \"$APP_NAME\"\ndokku config:set \"$APP_NAME\" KEY=value\n</code></pre> <p>Neat! One thing missing is the initial git clone, which would put our app into service. We can do that with the clone plugin:</p> <pre><code>dokku plugin:install https://github.com/crisward/dokku-clone.git clone\ndokku clone \"$APP_NAME\" git@github.com:heroku/node-js-sample.git\n</code></pre> <p>Info</p> <p>We'll be offering something even fancier soon, but props to Cris Ward for maintaining such a useful plugin!</p> <p>You now have a fully provisioned app on a new server on server boot. Your application downtime with this methodology decreases signficantly, and in many cases, this is enough to keep your business running.</p> <p>Info</p> <p>For folks using Dokku plugins for datastores, restoring service when all your data was stored on a non-existent server is a longer conversation with no easy solutions. At this time, none of the datastore plugins directly support running in HA mode, though this is something worth investigating. At this time, using managed datastore providers such as AWS RDS, CloudAMQP, etc. are the suggested methods for having HA datastore solutions.</p>","tags":["dokku","provisioning","automation"]},{"location":"automation/automating-dokku-setup/#a-brief-introduction-to-configuration-management","title":"A brief introduction to Configuration Management","text":"<p>Some of our users may be provisioning quite a few apps to a server, or the same server many times, or even managing a dozen servers for various clients. How do you handle that without a ton of bespoke bash scripts? How do you provision new applications without a tangle of <code>if</code> statements, in a DRY way? There are a few answers, but one common answer is to use a configuration management tool</p> <p>Configuration management tools provide common libraries and patterns for organizing server automation code. There are quite a few different tools in the config management space, but the one we're going show off is Ansible.</p> <p>Ansible requires python to run on a server. Assuming we're on an Ubuntu-based server, the following are roughly the installation instructions:</p> <pre><code>sudo apt-add-repository -y ppa:ansible/ansible\nsudo apt-get update\nsudo apt-get install -y ansible\n</code></pre> <p>Ansible provides an abstraction for executing python modules by writing small bits of yaml. Here is an example for running ansible against the local server. Place the following in a file called <code>dokku.yml</code></p> <pre><code>---\n- hosts: dokku\n  tasks:\n  - name: dokku repo\n    apt_repository:\n      filename: dokku\n      repo: 'deb https://packagecloud.io/dokku/dokku/ubuntu/ {{ ansible_lsb.codename|lower }} main'\n      state: present\n\n    - name: install dokku\n      apt:\n        pkg: dokku\n        state: installed\n        update_cache: true\n</code></pre> <p>The above invokes python modules that takes the above as configuration and:</p> <ul> <li>creates an apt repository file for dokku</li> <li>ensures dokku is installed, updating the apt cache if apt isn't aware of it</li> </ul> <p>To run the above, we'll need to create a <code>hosts</code> file. I've created a <code>dokku</code> group with the IP of the server I'm going to target.</p> <pre><code>[dokku]\n127.0.0.1\n</code></pre> <p>Now that everything is setup, we can just run the following to execute our provisioning code:</p> <pre><code>ansible-playbook -i hosts -s dokku.yml\n</code></pre>","tags":["dokku","provisioning","automation"]},{"location":"automation/automating-dokku-setup/#provisioning-many-dokku-appsservers-with-ansible","title":"Provisioning many Dokku apps/servers with Ansible","text":"<p>Now that we have a bare minimum ansible setup, we can iterate on this to provision actual Dokku applications. The following will create an app if it does not exist</p> <pre><code>---\n- hosts: dokku\n  tasks:\n    - name: does the node-js-app app exist\n      shell: dokku apps:exists node-js-app\n      register: app_exists\n      ignore_errors: True\n\n    - name: create an app\n      shell: dokku apps:create node-js-app\n      when: app_exists.rc == 1\n</code></pre> <p>This is pretty good so far, and uses the built-in <code>shell</code> Ansible libraries to do heavy lifting. However, the following would be much better:</p> <pre><code>---\n- hosts: dokku\n  tasks:\n    - name: dokku apps:create node-js-app\n      dokku_app:\n        app: node-js-app\n</code></pre> <p>The above would use a custom <code>dokku_app</code> Ansible library for provisioning applications, building upon the porcelain we covered previously.</p> <p>Info</p> <p>For our patreon followers, the code for the <code>dokku_app</code> library will be made available, as well as future plans around Ansible integration.</p>","tags":["dokku","provisioning","automation"]},{"location":"automation/automating-dokku-setup/#combining-the-methods-into-one","title":"Combining the methods into one","text":"<p>Assuming we have a repository with our server provisioning code - the yaml and hosts files - we can use the following user-data for automatically setting up a dokku server on boot.</p> <pre><code>#!/bin/bash\n\n# install ansible\nsudo apt-add-repository -y ppa:ansible/ansible\nsudo apt-get update\nsudo apt-get install -y ansible git\n\n# clone your infra repo\ngit clone git@example.git:infra /tmp/infra\n\n# provision the server\npushd /tmp/infra &gt; /dev/null\nansible-playbook -i hosts -s dokku.yml\n</code></pre>","tags":["dokku","provisioning","automation"]},{"location":"automation/automating-dokku-setup/#going-further","title":"Going Further","text":"<p>Once you have an <code>infra</code> repository containing the provisioning scripts for your servers, the next step is to do all Dokku configuration from this repository. This helps ensure migrating to a new server is as painless as possible, making service restoration a breeze.</p> <p>If you're using Dokku - especially for commercial purposes - consider donating to project development via Github Sponsors, OpenCollective, or Patreon. Funds go to general development, support, and infrastructure costs.</p>","tags":["dokku","provisioning","automation"]},{"location":"network/connect-to-host-processes/","title":"Connecting to network processes running directly on the host","text":"<p>On occasion, it may be necessary to connect to processes that are running on the same host but not within a docker container. Users may opt to perform this via either host-based networking or by using a host gateway.</p>","tags":["dokku","network"]},{"location":"network/connect-to-host-processes/#host-networking","title":"Host Networking","text":"<p>Using host-based networking allows processes running within Docker containers to completely bypass the networking stack. Processes within containers will listen directly on the host. In effect, this means that a process within a container listening on port 80 will also be listening on the host via port 80, and no other process on the host can utilize that port until the container process vacates it.</p> <p>Another by-product of utilizing host networking is that connecting to <code>127.0.0.1:$PORT</code> within a container will allow the container to connect to any process running on the host that is listening on <code>$PORT</code> or any other container that is listening on <code>$PORT</code> and utilizing host-based networking.</p> <p>To use host-based networking, start by adding the <code>--net=host</code> option to the app. For this example, the option will be added to all three phases.</p> <pre><code>dokku docker-options:add node-js-app build,deploy,run --net=host\n</code></pre> <p>The various phases provide differing functionality:</p> <ul> <li><code>build</code>: Allows build processes to talk to the host. Only applies to <code>herokuish</code>-based builds</li> <li><code>deploy</code>: All deployed containers will be able to communicate on host networking.</li> <li><code>run</code>: All processes in one-off (<code>dokku run</code>) and cron containers will be able to communicate on the host network.</li> </ul> <p>Once the option is added, the app must be rebuilt. Docker options will otherwise not come into effect as running containers are largely immutable and their network layer cannot change.</p> <pre><code>dokku ps:rebuild node-js-app\n</code></pre> <p>In a new shell session, start a process on the host to respond to requests. A <code>python3</code> server can serve up some temporary files:</p> <pre><code>mkdir /tmp/test-server\ncd /tmp/test-server/\necho \"hello world\" &gt; /tmp/test-server/index.html\npython3 -m http.server\n</code></pre> <p>Finally, in your original shell session, enter the app and make a request to the test process. The hostname for requests will be <code>127.0.0.1</code>. Note that this assumes <code>curl</code> is available within the container:</p> <pre><code>dokku enter node-js-app web\ncurl 127.0.0.1:8000\n</code></pre> <p>A <code>hello-world</code> message should be the response.</p> <p>Note that any process within a host-based network, host-based processses listening on either all interfaces or host-based processes listening on localhost will be accessible to the container with host-based networking.</p>","tags":["dokku","network"]},{"location":"network/connect-to-host-processes/#host-gateway","title":"Host Gateway","text":"<p>Rather than expose a process directly on a host, a host-gateway can be attached to the container. This allows for more complex networking usage while exposing the host as a dns entry in the container. Additionally, ports used by container processes are not reserved on the host, allowing for overlap across multiple containers.</p> <p>Start by adding the <code>--add-host=host.docker.internal:host-gateway</code> option to the app. For this example, the option will be added to all three phases.</p> <pre><code>dokku docker-options:add node-js-app build,deploy,run --add-host=host.docker.internal:host-gateway\n</code></pre> <p>The various phases provide differing functionality:</p> <ul> <li><code>build</code>: Allows build processes to talk to the host. Only applies to <code>herokuish</code>-based builds</li> <li><code>deploy</code>: All deployed containers will be able to communicate on host networking.</li> <li><code>run</code>: All processes in one-off (<code>dokku run</code>) and cron containers will be able to communicate on the host network.</li> </ul> <p>Once the option is added, the app must be rebuilt. Docker options will otherwise not come into effect as running containers are largely immutable and their network layer cannot change.</p> <pre><code>dokku ps:rebuild node-js-app\n</code></pre> <p>In a new shell session, start a process on the host to respond to requests. A <code>python3</code> server can serve up some temporary files:</p> <pre><code>mkdir /tmp/test-server\ncd /tmp/test-server/\necho \"hello world\" &gt; /tmp/test-server/index.html\npython3 -m http.server\n</code></pre> <p>Finally, in your original shell session, enter the app and make a request to the test process. The hostname for requests will be <code>host.docker.internal</code>. Note that this assumes<code>curl</code> is available within the container:</p> <pre><code>dokku enter node-js-app web\ncurl host.docker.internal:8000\n</code></pre> <p>A <code>hello-world</code> message should be the response.</p> <p>Note that only host processes listening on all interfaces - <code>0.0.0.0</code> - will be accessible via this method. Attempting to communicate to a host process listening on localhost - <code>127.0.0.1</code> - will result in a failure to connect.</p>","tags":["dokku","network"]},{"location":"network/connect-to-host-processes/#which-method-should-you-choose","title":"Which method should you choose?","text":"<p>Ultimately, each method has tradeoffs. Host-based networking allows complete access to networking on the host, trading security for simplicity, while host gateways provide better security in exchange for requiring that a process listen on all interfaces. The method you choose depends on your needs, and each should be considered after weighing the pros and cons for your situation.</p> <p>The Dokku project recommends host-gateway method for most cases, though users should feel free to pick what works best for their app.</p>","tags":["dokku","network"]},{"location":"network/inter-app-communication/","title":"Inter-app Communication in Dokku","text":"<p>In the microservice world, it may be necessary to communicate from one app container to another. Dokku makes this fairly straightforward by building upon docker networking.</p>","tags":["dokku","network"]},{"location":"network/inter-app-communication/#creating-a-network","title":"Creating a network","text":"<p>In order to communicate across multiple containers - whether they be within the same app or separate apps - a Docker network must first be created. This can be performed manually via the <code>dokku network:create</code> command. This creates an attachable network, allowing containers to be associated with the network at a later date.</p> <pre><code>dokku network:create custom-network\n</code></pre> <p>Note that the following network names are invalid:</p> <ul> <li>none</li> <li>bridge</li> <li>host</li> </ul>","tags":["dokku","network"]},{"location":"network/inter-app-communication/#attaching-an-app-to-the-network","title":"Attaching an app to the network","text":"<p>Dokku allows users to specify different phases for network attachment. While users will generally want to utilize <code>attach-post-deploy</code> as it will ensure the app is healthy before exposing it on the network, there are specific use cases for each phase:</p> <ul> <li><code>attach-post-create</code>: Associates the network after a container is created but before it is started. Commonly used for cross-app networking.</li> <li><code>attach-post-deploy</code> Associates the network after the deploy is successful but before the proxy is updated. Used for cross-app networking when healthchecks must be invoked first.</li> <li><code>initial-network</code>: Associates the network at container creation. Typically blocks access to services and external routing, and is almost always the incorrect network phase.</li> </ul> <p>For the purposes of this tutorial, we will use <code>attach-post-create</code>.</p> <pre><code>dokku network:set node-js-app attach-post-create custom-network\n</code></pre> <p>The above is sufficient when communicating with different processes running under the same app, but if communicating across applications, each app must be added to the same network.</p>","tags":["dokku","network"]},{"location":"network/inter-app-communication/#connecting-to-processes","title":"Connecting to processes","text":"<p>When a container created for a deployment is being attached to a network - regardless of which network property was used - a network alias of the pattern <code>APP.PROC_TYPE</code> will be added to all containers. This can be used to load-balance requests between containers. For an application named <code>node-js-app</code> with a process type of web, the network alias - or resolvable DNS record within the network - will be:</p> <pre><code>node-js-app.web\n</code></pre> <p>The fully-qualified URL for the resource will depend upon the <code>PORT</code> being listened to by the application. Applications built via buildpacks will have their <code>PORT</code> environment variable set to <code>5000</code>, and as such internal network requests for the above example should point to the following:</p> <pre><code>http://node-js-app.web:5000\n</code></pre> <p>Info</p> <p>[!IMPORTANT] Applications may listen on other ports, and typically do in the case of Dockerfile deployments. For more information on how ports are specified for applications, please refer to the port management documentation.</p> <p>If connecting from the <code>node-js-app</code> to the <code>python-app</code>'s <code>web</code> process that is listening on port 5000, we can try the following:</p> <pre><code>dokku enter node-js-app web\ncurl http://python-app.web:5000\n</code></pre> <p>Other types of requests - tcp, udp, grpc - will also work with the appropriate library.</p>","tags":["dokku","network"]},{"location":"other/deploying-an-image-without-a-registry/","title":"Deploying an image without a registry","text":"<p>To deploy an image from CI without an intermediate registry, we can run the following series of commands.</p> <p>Note</p> <p>This tutorial assumes the app being deployed is named <code>node-js-app</code> and the Dokku server's hostname is <code>dokku.me</code>. Please modify these values as appropriate.</p>","tags":["dokku","deploying"]},{"location":"other/deploying-an-image-without-a-registry/#building-the-image","title":"Building the image","text":"<p>First, we'll assume the image is built. The following is one example for building a docker image, though your setup may vary. The image repository must not be <code>dokku/</code>, as that namespace is used internally for tagging images by Dokku.</p> <pre><code>docker image build --tag app/node-js-app:2935cc3d .\n</code></pre> <p>It is recommended to tag your image with a unique tag per build, as otherwise the deployment step becomes tricky. A good tag to use is the commit sha of your build, which is usually provided by your CI provider of choice.</p>","tags":["dokku","deploying"]},{"location":"other/deploying-an-image-without-a-registry/#loading-the-image-onto-the-host","title":"Loading the image onto the host","text":"<p>Next, we save the image to a file. This can be done with the <code>docker image save</code> command:</p> <pre><code>docker image save --ouput node-js-app.tar\n</code></pre> <p>The image must then be loaded on the remote server. This should be performed with the <code>docker load</code> command, and must be performed by a user that has access to the docker daemon.</p> <pre><code>cat node-js-app.tar | ssh root@dokku.me \"docker load\"\n</code></pre> <p>Alternatively, you can save the image and load it in one command like so:</p> <pre><code>docker image save | ssh root@dokku.me \"docker load\"\n</code></pre> <p>Warning</p> <p>Because this command is not exposed by Dokku, a user other than <code>dokku</code> must be used for the ssh command.</p>","tags":["dokku","deploying"]},{"location":"other/deploying-an-image-without-a-registry/#deploying-the-image","title":"Deploying the image","text":"<p>Finally, we can deploy the image using the <code>git:from-image</code> Dokku command.</p> <pre><code>ssh dokku@dokku.me git:from-image node-js-app app/node-js-app:2935cc3d\n</code></pre>","tags":["dokku","deploying"]},{"location":"other/deploying-to-k3s/","title":"Deploying to a Dokku-managed k3s cluster","text":"<p>New in 0.33.0, Dokku natively supports deploying to a multi-node setup via k3s. Dokku can be used to connect k3s servers together to provide high availability and elastic capacity to your application, allowing you to weather outages of individual servers. The following tutorial briefly goes over how to setup and interact with Dokku.</p> <p>For more information, see the official scheduler-k3s documentation.</p>","tags":["dokku","k3s","cluster"]},{"location":"other/deploying-to-k3s/#single-node-cluster","title":"Single-node cluster","text":"<p>Initialize the cluster in single-node mode. This will start k3s on the Dokku node itself.</p> <pre><code># must be run as root\ndokku scheduler-k3s:initialize\n</code></pre> <p>The above command will initialize a cluster with the following configuration:</p> <ul> <li>etcd distributed backing store</li> <li>Wireguard as the networking flannel</li> <li>K3s automatic upgrader</li> <li>Longhorn distributed block storage</li> <li>Traefik configured to run on all nodes in the cluster</li> </ul> <p>Additionally, an internal token for authentication will be automatically generated. This is stored with k3s, and should be backed up appropriately.</p> <p>The K3s scheduler plugin will automatically pick up any newly configured registry backends and ensure nodes in the cluster have the credentials in place for pulling images from the cluster.</p> <pre><code># hub.docker.com\ndokku registry:login hub.docker.com $USERNAME $PASSWORD\n</code></pre> <p>To ensure images are pushed and pulled from the correct registry, set the correct <code>server</code> registry property. This can be set on a per-app basis, but we will set it globally here for this tutorial.</p> <pre><code>dokku registry:set --global server hub.docker.com\n</code></pre> <p>If using docker hub, you'll need to use a custom repository name. This can be set via a global template, allowing users access to the app name as the variable <code>AppName</code> as shown below.</p> <pre><code>dokku registry:set --global image-repo-template \"my-awesome-prefix/{{ .AppName }}\"\n</code></pre> <p>Additionally, apps should be configured to push images on the release phase via the <code>push-on-release</code> registry property.</p> <pre><code>dokku registry:set --global push-on-release true\n</code></pre> <p>As routing is handled by traefik managed on the k3s plugin, set the proxy plugin to <code>k3s</code> as well.</p> <pre><code>dokku proxy:set --global k3s\n</code></pre> <p>Ensure any other proxy implementations are disabled. Typically at least nginx will be running on the Dokku host and should be stopped if the host is used as load balancer.</p> <pre><code>dokku nginx:stop\n</code></pre> <p>Finally, set the scheduler to <code>k3s</code> so that app deploys will work on k3s.</p> <pre><code>dokku scheduler:set --global selected k3s\n</code></pre> <p>At this point, all app deploys will be performed against the k3s cluster.</p> <p>Note</p> <p>HTTP requests for apps can be performed against any node in the cluster. Without extra configuration, many other ports may also be available on the host. For security reasons, it may be desirable to place the k3s cluster behind one or more TCP load balancers while shutting off traffic to all cluster ports. Please consult your hosting provider for more information on how to provision a TCP load balancer and shut off all ports other than 22/80/443 access to the outside world.</p>","tags":["dokku","k3s","cluster"]},{"location":"other/deploying-to-k3s/#running-a-multi-node-cluster","title":"Running a multi-node cluster","text":"<p>Warning</p> <p>Certain ports must be open for cross-server communication. Refer to the K3s networking documentation for the required open ports between servers prior to running the command.</p> <p>For high-availability, it is recommended to add both worker and server nodes to the cluster. Dokku will default to starting the cluster with an embedded Etcd database backend, and is ready to add new worker or server nodes immediately.</p> <p>When running a multi-node cluster, initialize k3s with the <code>--taint-scheduling</code> flag. This will start the k3s on the Dokku node in server mode. Server nodes only allow critical addons to be run, such as the control plane, etcd, the load balancer, etc.</p> <pre><code># must be run as root\ndokku scheduler-k3s:initialize --taint-scheduling\n</code></pre> <p>When attaching an worker or server node, the K3s plugin will look at the IP associated with the <code>eth0</code> interface and use that to connect the new node to the cluster. To change this, set the <code>network-interface</code> property to the appropriate value.</p> <pre><code>dokku scheduler-k3s:set --global network-interface eth1\n</code></pre> <p>Dokku will connect to remote servers via the <code>root</code> user with the <code>dokku</code> user's SSH key pair. Dokku servers may not have an ssh key pair by default, but they can be generated as needed via the <code>git:generate-deploy-key</code> command.</p> <pre><code>dokku git:generate-deploy-key\n</code></pre> <p>This key can then be displayed with the <code>git:public-key</code> command, and added to the remote server's <code>/root/.ssh/authorized_keys</code> file.</p> <pre><code>dokku git:public-key\n</code></pre> <p>Multiple server nodes can be added with the <code>scheduler-k3s:cluster-add</code> command. This will ssh onto the specified server, install k3s, and join it to the current Dokku node in server mode.</p> <pre><code>dokku scheduler-k3s:cluster-add --role server --taint-scheduling ssh://root@server-1.example.com\n</code></pre> <p>If the server isn't in the <code>known_hosts</code> file, the connection will fail. This can be bypassed by setting the <code>--insecure-allow-unknown-hosts</code> flag:</p> <pre><code>dokku scheduler-k3s:cluster-add --role server --taint-scheduling --insecure-allow-unknown-hosts ssh://root@worker-1.example.com\n</code></pre> <p>Note</p> <p>Only the initial Dokku server will be properly configured for push deployment, and should be considered your git remote. Additional server nodes are for ensuring high-availability of the K3s etcd state. Ensure this server is properly backed up and restorable or deployments will not work.</p> <p>Worker nodes are used to run. To add an worker, run the <code>scheduler-k3s:cluster-add</code> with the <code>--role worker</code> flag. This will ssh onto the specified server, install k3s, and join it to the current Dokku node in worker mode. Workers are typically used to run app workloads.</p> <pre><code>dokku scheduler-k3s:cluster-add --role worker ssh://root@worker-1.example.com\n</code></pre>","tags":["dokku","k3s","cluster"]},{"location":"other/deploying-to-k3s/#deploying-an-app","title":"Deploying an app","text":"<p>To demonstrate multi-server functionality, we can deploy the Dokku smoke-test-app with the following commands.</p> <p>First, create the app:</p> <pre><code>dokku apps:create smoke-test-app\n</code></pre> <p>Next, add any desired domains to the app. If running a single-node cluster, the DNS for each domain should point to your Dokku node. For multi-node clusters, point any DNS records at your server node IP addresses.</p> <pre><code>dokku domains:set smoke-test-app.dokku.me\n</code></pre> <p>Finally, deploy the app. For demo purposes, we'll use the <code>git:sync</code> command against the Dokku server.</p> <pre><code>dokku git:sync --build smoke-test-app https://github.com/dokku/smoke-test-app.git\n</code></pre> <p>At this point, you should be able to browse to <code>smoke-test-app.dokku.me</code> in your browser to see the response from the app.</p>","tags":["dokku","k3s","cluster"]},{"location":"other/run-on-external-volume/","title":"Run on an External Volume","text":"<p>In order to leverage cloud-provider facilities like attachable volumes, (a.k.a. block storage) the following is an easy tutorial to achieve Dokku runs on them.</p> <p>Warning</p> <p>If the block storage is not available and attached on boot it is possible that containers will not correctly start. Please keep this in mind when considering moving Dokku and/or Docker to network attached storage.</p> <p>The following is intended to be executed on the dokku host machine as <code>root</code>. Say, for instance, that our volume is mapped into the systems as <code>/dev/vdb1</code>.</p> <p>Stop docker daemon</p> <pre><code>systemctl stop docker.socket\nsystemctl stop docker\n</code></pre> <p>Prepare the filesystem:</p> <pre><code>mkfs -t ext4 /dev/vdb1\nmkdir /mnt/volume\nmount /dev/vdb1 /mnt/volume\n</code></pre> <p>Move the old data directories:</p> <pre><code>mv /home/dokku /home/dokku.OLD\nmv /var/lib/docker /var/lib/docker.OLD\nmv /var/lib/dokku /var/lib/dokku.OLD\n</code></pre> <p>Move the data on the volume</p> <pre><code>mkdir /mnt/volume/home/\nmkdir -p /mnt/volume/var/lib/\nmv /home/dokku.OLD /mnt/volume/home/dokku\nmv /var/lib/dokku.OLD /mnt/volume/var/lib/dokku\nmv /var/lib/docker.OLD /mnt/volume/var/lib/docker\n</code></pre> <p>Prepare the mountpoints</p> <pre><code>mkdir /home/dokku\nmkdir /var/lib/dokku\nmkdir /var/lib/docker\nchown dokku:dokku /home/dokku   # respect the original ownership\nchmod 711 /var/lib/docker       # respect the original permissions\n</code></pre> <p>Mount bind</p> <pre><code>mount -o bind /mnt/volume/home/dokku /home/dokku\nmount -o bind /mnt/volume/var/lib/dokku /var/lib/dokku\nmount -o bind /mnt/volume/var/lib/docker /var/lib/docker\n</code></pre> <p>Start docker daemon</p> <pre><code>systemctl start docker.socket\nsystemctl start docker\n</code></pre> <p>At this point all should be working fine, please check it out.</p> <p>Then, let the changes be reboot-persistent</p> <pre><code>echo '/dev/vdb1 /mnt/volume ext4 defaults 0 2' | sudo tee -a /etc/fstab\necho '/mnt/volume/home/dokku /home/dokku none defaults,bind 0 0' | sudo tee -a /etc/fstab\necho '/mnt/volume/var/lib/dokku /var/lib/dokku none defaults,bind 0 0' | sudo tee -a /etc/fstab\necho '/mnt/volume/var/lib/docker /var/lib/docker none defaults,bind 0 0' | sudo tee -a /etc/fstab\n</code></pre>","tags":["dokku","provisioning"]},{"location":"other/using-websockets-in-dokku/","title":"Using Websockets with Nginx","text":"<p>Note</p> <p>The code for this tutorial is available on Github</p> <p>In many frameworks, a separate process must be run to expose websockets due to the underlying language in use. This tutorial assumes that is the case, and therefore your app is assumed to run two processes, a <code>web</code> and a <code>ws</code> process. The following is an example Procfile for our <code>websocket-example</code> application.</p> <pre><code>web: websocket-example web\nws: websocket-example ws\n</code></pre> <p>To route requests to the <code>ws</code> process, a custom <code>nginx.conf.sigil</code> will need to be placed into the app source. The latest is available here, though you may wish to get the one for your particular version of Dokku. Copy that file to <code>nginx.conf.sigil</code> in the root of your repository and commit it:</p> <pre><code>curl -L --output nginx.conf.sigil https://raw.githubusercontent.com/dokku/dokku/master/plugins/nginx-vhosts/templates/nginx.conf.sigil\ngit add nginx.conf.sigil\ngit commit -m \"feat: vendor nginx.conf.sigil\"\n</code></pre> <p>Next, add the following location block to the file. The are two locations that it can be added to, both after the <code>location /</code> block. The first block is for <code>http</code> support, while the latter is for <code>https</code> support. We can add it to both for simplicities sake:</p> <pre><code>  location /echo {\n    proxy_buffering off;\n    proxy_set_header Host $host;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Real-IP $remote_addr;\n\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n\n    proxy_pass http://{{ $.APP }}-ws;\n  }\n</code></pre> <p>In the above <code>location</code> block, the path is set to <code>/echo</code>. This is the path that the <code>ws</code> process responds to requests on. If your path is something else, this can be changed.</p> <p>Warning</p> <p>The <code>proxy_pass</code> line omits a trailing slash (<code>/</code>). This allows the request to flow to the <code>ws</code> process at <code>/echo</code>. If a trailing slash is added, then the request made to the <code>ws</code> process will be at <code>/</code>. Please see this stackoverflow answer for more details on how trailing slashes work with proxy pass.</p> <p>Once the <code>location</code> blocks are added, we can add the upstream block at the end of the file. The following upstream block assumes the <code>ws</code> process is listening on port <code>5000</code>, but this may be changed as appropriate.</p> <pre><code>upstream {{ $.APP }}-ws {\n{{ if not $.DOKKU_APP_WS_LISTENERS }}\n  server 127.0.0.1:65535; # force a 502\n{{ else }}\n{{ range $listeners := $.DOKKU_APP_WS_LISTENERS | split \" \" }}\n{{ $listener_list := $listeners | split \":\" }}\n{{ $listener_ip := index $listener_list 0 }}\n  server {{ $listener_ip }}:5000;{{ end }}\n{{ end }}\n}\n</code></pre> <p>Once the updates are made, commit the changes:</p> <pre><code>git add nginx.conf.sigil\ngit commit -m \"feat: route /echo to ws process\"\n</code></pre> <p>Note that we use the template variable <code>$.DOKKU_APP_WS_LISTENERS</code>, which maps to our <code>ws</code> process. If using a different process name, then the variable being listened to would be different. A few examples are below:</p> process name variable <code>ws</code> <code>$.DOKKU_APP_WS_LISTENERS</code> <code>websocket</code> <code>$.DOKKU_APP_WEBSOCKET_LISTENERS</code> <code>web-socket</code> <code>$.DOKKU_APP_WEB_SOCKET_LISTENERS</code> <p>One thing to note in the above nginx template snippet is the check for the variable <code>$.DOKKU_APP_WS_LISTENERS</code>. Without this check, a deploy that doesn't scale up the <code>ws</code> process will fail to produce a valid <code>nginx.conf</code> file, failing the deploy. The variable will only have a value with there are processes scaled up.</p> <p>At this point, assuming the codebase in question is similar to the websocket-tutorial, we can deploy the app and scale up our <code>ws</code> process, allowing websocket connections to flow through to your non-web process.</p> <pre><code>git push dokku master\ndokku ps:scale websocket-example ws=1\n</code></pre>","tags":["dokku","nginx","websockets"]},{"location":"plugins/creating-a-datastore-plugin/","title":"Creating a Datastore plugin","text":"<p>Ever wanted to write a datastore plugin? This tutorial shows how we create official datastore plugins.</p> <p>Info</p> <p>If you're using Dokku - especially for commercial purposes - consider donating to project development via Github Sponsors, OpenCollective, or Patreon. Funds go to general development, support, and infrastructure costs.</p>","tags":["dokku","plugins"]},{"location":"plugins/creating-a-datastore-plugin/#initializing-the-plugin","title":"Initializing the plugin","text":"<p>First, we'll start by cloning an existing datastore plugin. I'll choose the <code>postgres</code> plugin.</p> <pre><code>git clone https://github.com/dokku/dokku-postgres dokku-meillisearch\ncd dokku-meillisearch\nrm -rf .git\n</code></pre> <p>Once this is done, we can modify the <code>plugin.toml</code> to have the following contents:</p> <pre><code>[plugin]\ndescription = \"dokku meillisearch service plugin\"\nversion = \"0.0.1\"\n[plugin.config]\n</code></pre>","tags":["dokku","plugins"]},{"location":"plugins/creating-a-datastore-plugin/#reconfiguring-the-plugin","title":"Reconfiguring the plugin","text":"<p>Now begins the great find/replace. We'll do the following case-sensitive replacements:</p> <ul> <li><code>postgres</code> <code>meillisearch</code></li> <li><code>Postgres</code> <code>Meillisearch</code></li> <li><code>POSTGRES</code> <code>MEILLISEARCH</code></li> </ul> <p>After the find/replace, we'll need to configure the plugin correctly. There should be a <code>config</code> file that contains runtime configuration for the plugin. We'll need to change the following in this file:</p> <ul> <li><code>PLUGIN_DATASTORE_PORTS</code>: A bash array containing a list of ports exposed by the service. In many cases, this will be a single port. All ports should be listed here. The first port in the list is used when linking the service to an app.<ul> <li>For <code>meillisearch</code>, the config should look as follows <code>export PLUGIN_DATASTORE_PORTS=(7700)</code></li> </ul> </li> <li><code>PLUGIN_DATASTORE_WAIT_PORT</code>: This should be the primary port that Dokku waits to be ready when creating the service. Usually this will be the port used to link the service to an app.<ul> <li>For <code>meillisearch</code>, the config should look as follows <code>export PLUGIN_DATASTORE_WAIT_PORT=7700</code></li> </ul> </li> <li><code>PLUGIN_SCHEME</code>: The value of this is used in the DSN. Do not leave it blank. It can usually be the lowercase version of the datastore name, but sometimes may need to be something different.<ul> <li>For <code>meillisearch</code>, the config should look as follows <code>export PLUGIN_SCHEME=http</code></li> </ul> </li> <li><code>PLUGIN_DEFAULT_ALIAS</code>: This is used as the prefix for the <code>_URL</code> value. DATABASE_URL is pretty normal for sql datastores.<ul> <li>For <code>meillisearch</code>, the config should look as follows` export PLUGIN_DEFAULT_ALIAS=\"MEILLISEARCH\"</li> </ul> </li> </ul> <p>The <code>config</code> file also contains a <code>PLUGIN_UNIMPLEMENTED_SUBCOMMANDS</code> shell array. This contains a list of commands that are not supported by the plugin. For sql-like plugins, this is usually empty, but sometimes certain functionality is not supported by the datastore (such as backup/restore or connecting to the service using a repl). In our case, we'll set the following value.</p> <pre><code>export PLUGIN_UNIMPLEMENTED_SUBCOMMANDS=(\"backup\" \"backup-auth\" \"backup-deauth\" \"backup-schedule\" \"backup-schedule-cat\" \"backup-set-encryption\" \"backup-unschedule\" \"backup-unset-encryption\" \"clone\" \"connect\" \"export\" \"import\")\n</code></pre> <p>This can always be revisited in the future as functionality becomes available to the datastore.</p> <p>Once this is set, we need to update the default Docker image the datastore plugin will use. This is contained within the <code>Dockerfile.</code> As of the time of writing, the latest stable image tag is <code>v0.23.1</code>, so we'll have the following as the <code>Dockerfile</code> contents:</p> <pre><code>FROM getmeili/meilisearch:v0.23.1\n</code></pre> <p>These cover the general changes. Now on to function updates.</p>","tags":["dokku","plugins"]},{"location":"plugins/creating-a-datastore-plugin/#customizing-commands","title":"Customizing Commands","text":"<p>90% of the plugin is templated, but datastore-specific functions are stored in the <code>functions</code> file. We'll go over each of these below (and describe the customizations for <code>meilisearch</code>).</p> <ul> <li><code>service_connect</code>: Connects to the datastore via a repl. The repl must be available in the base image in use, and not any customization.<ul> <li>For <code>meillisearch</code>, we'll replace the existing <code>psql</code> call with <code>dokku_log_fail \"Not yet implemented\"</code></li> </ul> </li> <li><code>service_create</code>: Usually only customized if there are password needs (either the datastore doesn't support a password or supports a root password in addition to the normal one).<ul> <li>For <code>meillisearch</code>, we don't need to customize anything.</li> </ul> </li> <li> <p><code>service_create_container</code>: The meat and potatos. This creates the container and intiailizes data for the container (if necessary).</p> <ul> <li> <p>For <code>meillisearch</code>, we can drop the code that initiliazes container database (from ~line 96-105, which contains the <code>service_port_unpause</code> call). Additionally, the <code>ID=$(docker run ...)</code> command should become the following:</p> <pre><code>ID=$(docker run --name \"$SERVICE_NAME\" $MEMORY_LIMIT $SHM_SIZE -v \"$SERVICE_HOST_ROOT/data:/data.ms\" -e \"MEILI_MASTER_KEY=$PASSWORD\" -e \"MEILI_HTTP_ADDR=0.0.0.0:7700\" -e \"MEILI_NO_ANALYTICS=true\" --env-file=\"$SERVICE_ROOT/ENV\" -d --restart always --label dokku=service --label dokku.service=meillisearch \"$PLUGIN_IMAGE:$PLUGIN_IMAGE_VERSION\" $CONFIG_OPTIONS)\n</code></pre> </li> </ul> </li> <li> <p><code>service_export</code>: Used for exporting the service data. You can implement this if the container has some way to export the data to stdout</p> <ul> <li>For <code>meillisearch</code>, we'll replace the existing <code>psql</code> call with <code>dokku_log_fail \"Not yet implemented\"</code></li> </ul> </li> <li><code>service_import</code>: Analogous to <code>service_export</code>, used for importing the service data. You can implement this if the container has some way import the data from stdin.<ul> <li>For <code>meillisearch</code>, we'll replace the existing <code>psql</code> call with <code>dokku_log_fail \"Not yet implemented\"</code></li> </ul> </li> <li><code>service_start</code>: The only time this is customized is when the service either has no passwords (so the password check is removed) or has a secondary, root password (so we add another check).<ul> <li>For <code>meillisearch</code>, the existing checks the <code>Postgres</code> plugin performs are enough.</li> </ul> </li> <li><code>service_url</code>: This outputs the default DSN-formatted connection string. Docker exposes other variables containing just IPs, PORTs, and other values from the config, so it is heavily encouraged to not come up with your own format here.<ul> <li> <p>For <code>meillisearch</code>, this should become the following:</p> <pre><code>echo \"$PLUGIN_SCHEME://:$PASSWORD@$SERVICE_DNS_HOSTNAME:${PLUGIN_DATASTORE_PORTS[0]}\"\n</code></pre> </li> </ul> </li> </ul>","tags":["dokku","plugins"]},{"location":"plugins/creating-a-datastore-plugin/#fixing-tests","title":"Fixing tests","text":"<p>Usually the following should be modified for tests. Below contains the changes for our meillisearch plugin.</p> <ul> <li>Tests matching unimplemented commands should be removed. For <code>meillisearch</code>, this means deleting the following files:<ul> <li><code>tests/service_clone.bats</code></li> <li><code>tests/service_connect.bats</code></li> <li><code>tests/service_export.bats</code></li> <li><code>tests/service_import.bats</code></li> </ul> </li> <li>Port references should be updated. In our case, a find/replace of <code>5432</code> with <code>7700</code> is enough for this.</li> <li><code>username:password</code> need to conform to how the datastore works. For <code>meillisearch</code>, we can do two find-replacements:<ul> <li><code>//u:p</code> =&gt; <code>//:p</code></li> <li><code>//meillisearch:$password</code> =&gt; <code>//:$password</code></li> </ul> </li> <li>The plugin scheme should be updated. This is done with two  find/replace calls:<ul> <li><code>meillisearch://</code> =&gt; <code>http://</code></li> <li><code>meillisearch2</code> =&gt; <code>http2</code></li> </ul> </li> <li>The \"database\" in the DSN should be updated to match the plugin's <code>service_url</code> format. In our case, we'll need a few find-replacements:<ul> <li><code>/db\"</code> =&gt; <code>\"</code> (basically removing the suffix)</li> <li><code>/l\"</code> =&gt; <code>\"</code> (basically removing the suffix)</li> <li><code>/test_with_underscores\"</code> =&gt; <code>\"</code> (basically removing the suffix)</li> <li><code>/db</code>: there will be one instance of this in a <code>config:set</code> call. The string should just be removed.</li> </ul> </li> <li>The <code>dsn</code> key should be updated to match the <code>PLUGIN_DEFAULT_ALIAS</code>. For <code>meillisearch</code>, we can do the following find/replace:<ul> <li><code>DATABASE_URL</code> =&gt; <code>MEILLISEARCH_URL</code></li> </ul> </li> </ul>","tags":["dokku","plugins"]},{"location":"plugins/creating-a-datastore-plugin/#regenerating-the-readmemd","title":"Regenerating the README.md","text":"<p>The readme is generated by reading through the plugin source and generating help based on the <code>config</code> file and the source of each subcommand. It is enhanced by files in the <code>docs</code> folder. For our use case, we'll remove everything in the <code>docs</code> folder except for <code>docs/README.</code></p> <p>This can be done in a single call to <code>bin/generate</code> a script included with each plugin that requries <code>python3</code>.</p>","tags":["dokku","plugins"]},{"location":"plugins/creating-a-datastore-plugin/#commiting-everything","title":"Commiting everything","text":"","tags":["dokku","plugins"]},{"location":"plugins/creating-a-datastore-plugin/#if-everything-went-well-we-can-commit-and-push-our-new-service-plugin-to-github-the-plugin-should-automatically-run-tests-in-github-actions-at-which-point-you-can-catch-any-lingering-errors","title":"If everything went well, we can commit and push our new service plugin to Github. The plugin should automatically run tests in Github Actions, at which point you can catch any lingering errors.","text":"<p>If you're using Dokku - especially for commercial purposes - consider donating to project development via Github Sponsors, OpenCollective, or Patreon. Funds go to general development, support, and infrastructure costs.</p>","tags":["dokku","plugins"]}]}